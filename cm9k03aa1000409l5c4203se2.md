---
title: "Vector Database(1) - 벡터와 유사도"
seoTitle: "Vectors and similarity in databases"
seoDescription: "Explore the concepts of vectors, cosine similarity, and distance in product recommendation models and their applications in this insightful article"
datePublished: Wed Apr 16 2025 14:02:07 GMT+0000 (Coordinated Universal Time)
cuid: cm9k03aa1000409l5c4203se2
slug: vector-database1
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1744810785391/4e605a62-69e7-4790-8114-83a9c023c460.jpeg
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1744812108413/e58edd0d-43fd-4d84-b6fd-8ff82cc17c89.jpeg
tags: vector, recommender-systems, vector-database, 67kh7ysw642w7j207ysw67kg7j207iqk, 67kh7ysw

---

## 벡터(Vector)

잘 안써본 사람들에게는 생소할 수 있으나 요새는 Huggingface 나 Ollama 등을 통해 엔터프라이즈 급에서 잘 만들어진 LLM 을 작게나마 로컬에서 서빙해보고, 임베딩할수 있는 시대가 되었기에 **벡터** 개념에 친숙한 사람들도 많아졌고, 사용성도 점점 높아지는 추세인것 같다. 나도 실제 프로덕션에서 사용하고 있는 만큼 오늘은 Vector 에 대한 내 지식도 정리하는 시간을 가져보려고 한다.

## 유사도와 거리

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1744809712440/4f2fa33a-d3ce-4080-bd78-3f100014e858.png align="center")

고등학교 수학시간에 배워서 다들 알고 있겠지만 벡터는 방향을 가지고 있다. **코싸인 유사도**는 얼마나 같은 방향을 향해 힘을 쏟고 있는가를 중점적으로 본다. 파이썬 코드로 간단하게 그려본 예시를 함께 살펴보자. A 와 B 벡터를 살펴보면 같은 방향으로 나아가고 있음을 알 수 있다.

그러므로 두 벡터의 코싸인 유사를 구해보면 최댓값인 1이 나온다 (코싸인 유사도의 범위는 -1 ~ 1 이다). 여기서 왜 방향성을 보는지 의문을 가질 수 있다. 물론 어떻게 해석하냐에 따라 달라질수 있지만 우리가 추천 모델을 구성한다고 해보자. 예를 들어, A 와 B 가 가르키는 방향에 A 라는 상품군이 존재한다고 했을때 여태까지 통계를 기반으로 만들어진 두 벡터 A, B 가 가르키는 방향은 상품 A 를 향해 달려가고 있다고 생각해볼수 있다.

즉, 간단하게 생각해서 A 와 B 가 A 라는 상품군에 다가가는 힘의 크기는 다를 수 있지만 나아가고자 하는 방향성은 같을 수 있다고 생각해볼 수 있는 것이다. 따라서 이러한 가설안에서는 A 와 B 에게 A 상품군을 보여주는 추천 모델을 구상해볼수 있다.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1744810455850/95c95643-88ff-4495-a4de-119fa7ca2c04.jpeg align="center")

다만 여기서 의문을 하나 가져볼순 있다. 그러면 **거리**는 어떤 의미를 나타낼 수 있을까? 위에서 A, B 벡터를 보면 같은 방향을 향해 나아가고 있지만 둘의 길이(norm) 은 확연히 다르다. 이는 어떤 의미를 나타낼까? 벡터를 어떻게 그리냐에 따라 다르겠지만, 오늘 예시 추천 시스템에서는 **“유저의 구입”**, **“유저의 해당 상품군 조회”** 등의 **파라미터(Parameter)** 와 **임의의 계수(가중치)** 로 계산했다고 해보자.

이러한 가정속에서는 유저가 얼마나 해당 상품에 대해 **열정적**인지 파악해볼 수 있다. 즉, A 와 B 가 열심히 한 방향을 향해 달려가고 있지만 A 는 정말 **A 상품군을 사랑하는 유저**일 확률이 높다. 따라서, 이런 유저는 정말 열성적인 팬이기에 오히려 B 유저에게 쿠폰을 주거나 혜택을 주어 B 유저도 A 유저만큼 열정적으로 변하게 만드는 것이 좋을 수 있다.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1744811442635/d6410e41-48f5-4b54-aa89-f0f0bf45077e.png align="center")

다만 지금의 가정은 거리와 방향성을 모두 고려했을때다, 우리는 A 와 B 모두 같은 방향을 보고 달리는 벡터이기 때문에 이러한 가정을 세울수 있었다. 만약, 거리가 가까울수록 더 유사하다고 가정해보자. A 와 B 사이에는 1.41 의 간격이 존재한다. 만약, 위 그림과 같이 다른 방향을 보고 있는 D 와의 거리가 1.40 으로 0.01 짧다면 과연 A 와 D 가 우리가 원하고자 하는 추천 모델에서 적절한 제품을 A 에게 추천해줄수 있을까?

**똑같은 인터랙션이 많이 일어난다면 두 벡터 A, D 가 아마 다른 제품을 향해 달려갈 확률**이 높다고 생각한다. 즉, 우리가 가정한 모델에 속에서 벡터에서 길이란 어떻게 보면 **정량적인 지표**에 불과할 확률이 높다. 그래서 A 라는 유저가 특정 방향을 향해 단기간내에 임계치 이상의 값에 도달한다면, 편향을 줄이기 위해 다른 물품을 섞어 보여주는등 관여할 수는 있겠지만, 전반적으로 추천 모델에서는 방향이 주를 이룬다고 생각할 수 있다.

### 마치며

오늘은 벡터로 수학적인 관점보다 프로덕트 관점에서 조금 풀어본것 같다. 사실 코싸인 유사도 라는것 자체가 이미 정규화하여 방향의 유사성만을 바라보기에 다르게 해석하면 **크기(Magnitude)** 라는 정보를 소실하게 된다. 그렇기에 자신이 운영하는 서비스에서 어떤 정보가 더 중요한지, 그리고 어떻게 실험해봐야 하는지 여러가지 정보들의 중요성을 따지면서 추천모델을 구축하는 것이 중요하다.

다음에는 기술적으로 이 벡터 데이터를 저장할수 있는 벡터 데이터베이스에 관한 글을 적어보려고 한다.